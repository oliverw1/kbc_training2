# Data Engineering with Pyspark

* Context: 
  
  Classroom lectures given at KBC, a financial institute in Belgium, between 
  the dates of
  
   * (v1) 2019-05-13 and 2019-05-15.
   * (v2) 2020-09-14 and 2020-09-25

* Objectives:

  - Introduce good data engineering practices.
  - Illustrate modular and easily testable data transformation pipelines using 
    Pyspark.
  
* Audience:

  Employees of KBC involved in writing (porting?) transformation pipelines. 
  General knowledge level: junior - medior.
  
  Participants were asked (by KBC personel) to go through two online Python
  courses prior to participation.
  
  (v2): participants were split into groups of expected similar knowledge level,
  based on the outcome of a 10-question survey

* Approach:

  Lecturer first sets the foundations right for Python development and gradually
  builds up to PySpark data pipelines.
  There is a high degree of participation expected from the students: they will
  need to write code themselves and reason on topics, so that they can better 
  retain the knowledge. 
  
  Course notes will be made available _after_ the day sessions. Materials 
  needed for the exercices will be provided through Github directly.